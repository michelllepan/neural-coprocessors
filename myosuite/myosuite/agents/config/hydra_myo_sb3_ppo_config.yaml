default:
    - override hydra/output: local
    - override hydra/launcher: local

env               :   'myoHandPoseRandom-v0' #myosuite-v1          # placeholder name, not a real env
algorithm         :   PPO
seed              :   123
n_env             :   32
n_eval_env        :   5

# PPO object
policy            : 'MlpPolicy'
learning_rate     : 1e-5 
batch_size        : 256
gamma             : 0.95

# PPO.learn function
total_timesteps   : 150000
log_interval      : 1000

eval_freq : 1000000
restore_checkpoint_freq : 500000
save_freq : 10000000

policy_kwargs:                                              # Policy parameters (initial STD and architecture)
  net_arch:
    - pi: [256, 128]
      vf: [256, 128]


# Algorithm hyperparameters : if alg requires additional params, can be specified here (or defaults will be used)
alg_hyper_params  :   {'device': 'cpu'}

job_name          :   ppo_sb3_${env}

hydra:
    job:
        name: ${env}